{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the around 100.000 reviews of the most reviewed amazon products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amazon_df = pd.read_csv('../data/amazon_sorted/most_populair_products.csv')\n",
    "amazon_df = amazon_df.drop(columns='index').dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the most reviewed product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8799\n"
     ]
    }
   ],
   "source": [
    "product_df = amazon_df[amazon_df['product_id'] == amazon_df.iloc[0]['product_id']]\n",
    "print(len(product_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a topic model, containing the 10 most important topics of the reviews. \\\n",
    "The topic model ```fit_transform``` function returns predictions, which are two lists: the first is a list of predicted topic per review, the second is a list of topic probability distributions per review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8799\n",
      "    Topic  Count                           Name\n",
      "0      -1   5942               -1_the_to_and_is\n",
      "1       0    490                0_the_and_to_of\n",
      "2       1    487        1_easy_sound_good_great\n",
      "3       2    473                 2_tv_he_my_and\n",
      "4       3    254                 3_to_the_tv_it\n",
      "5       4    224  4_wireless_the_headphones_and\n",
      "6       5    220          5_works_great_it_good\n",
      "7       6    195        6_the_tv_and_headphones\n",
      "8       7    191              7_these_tv_and_to\n",
      "9       8    164        8_the_sennheiser_and_is\n",
      "10      9    159            9_static_the_and_to\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "nr_topics = 10\n",
    "topic_model = BERTopic(nr_topics=nr_topics, calculate_probabilities=True)\n",
    "\n",
    "predictions = topic_model.fit_transform(product_df['review_body'])\n",
    "print(len(predictions[1]))\n",
    "print(topic_model.get_topic_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Didn't work with the tv for which it was purchased.\", \"I purchased this used from Amazon, though the product in the box looked as if it hadn't been opened.<br />It was easy to connect and works well. I use it for watching TV after my spouse is asleep. It's perfect for that, though with my 40&#34; Sony TV, the sound from the TV speakers shuts off when the 3.5mm headphone jack has something plugged into it. This means you need to plug the base connector in when these are in use, and unplug when you want sound from the TV speakers. To get around this I purchased a Fiio D3 (D03K) Digital to Analog Converter (comes with optical cable) here on Amazon and connected the headphone base unit with an optical cable from the optical audio out port on my TV. Now I only need to mute the TV speakers using the mute button on the TV remote and listen to the headphones adjusting their volume with the volume control on the headset.<br />The reception on the headphones work best when the volume level on your TV is turned up a bit so the bass unit can recognize the signal.<br /><br />For music? Well, if you're an audiophile you might be bothered by occasional static pops from the wireless function, but for TV watching these are perfect. The wireless function means there's no cord stretched across the room for someone to trip over. The used price was what I think of as a great bargain. Thank You Amazon-\", \"My husband loves these headphones.  We have two pair.  With the Sony TV it plugs into an earphone outlet when using the headphones and we have to remove it from that outlet to receive normal volume.  With the new TV it plugs into an optical outlet and we don't have to get up, go to the TV and remove the plug in order to get normal volume..  You do need an optical to analog converter though.\", 'base was not working on delivery, likely a defect. However i missed the return window and thus stuck with it', 'initially had a hard time with the connection to the base, but got it in and works great.', 'These will be going back before I ever even got the power connected.  The power cable does not fit into the main base and my fingers are raw from trying to jam it in.  Stupid design, not worth my time.']\n",
      "([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [1.63920562e-05, 3.00569639e-04, 1.66404196e-04, 4.44364282e-05,\n",
      "        7.96275111e-01, 2.47951012e-04, 3.53439676e-05, 1.46740851e-04,\n",
      "        3.46476057e-05, 5.66453358e-05],\n",
      "       [1.39811323e-03, 2.56132316e-02, 1.41798031e-02, 3.78792139e-03,\n",
      "        4.24870051e-01, 2.11150686e-02, 3.01429254e-03, 1.25737289e-02,\n",
      "        2.95516928e-03, 4.82986088e-03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [1.97675615e-03, 2.04802866e-02, 1.39788402e-02, 3.75736336e-03,\n",
      "        4.23593681e-01, 1.46845931e-02, 4.87460833e-03, 7.93055846e-03,\n",
      "        5.74374780e-03, 6.52362957e-03],\n",
      "       [3.90495174e-28, 4.05756055e-27, 2.75846178e-27, 7.41542829e-28,\n",
      "        9.68253684e-01, 2.89369815e-27, 9.63473965e-28, 1.56470906e-27,\n",
      "        1.13943567e-27, 1.28798736e-27],\n",
      "       [3.55994107e-22, 2.66453266e-21, 2.57846238e-21, 7.58855555e-22,\n",
      "        9.60181044e-01, 2.25662360e-21, 1.15591845e-21, 1.48699267e-21,\n",
      "        1.65244569e-21, 1.51588924e-21],\n",
      "       [1.43292876e-05, 1.10657940e-04, 1.06274391e-04, 3.11383134e-05,\n",
      "        8.30443802e-01, 9.34113882e-05, 4.72041616e-05, 6.11047582e-05,\n",
      "        6.69960770e-05, 6.22928579e-05],\n",
      "       [3.20185031e-04, 2.36582992e-03, 2.29263241e-03, 6.76779954e-04,\n",
      "        7.31938077e-01, 1.99963086e-03, 1.02770246e-03, 1.32113500e-03,\n",
      "        1.50856466e-03, 1.34643713e-03],\n",
      "       [1.13244865e-11, 8.69668548e-11, 8.96449793e-11, 2.67874946e-11,\n",
      "        9.23860961e-01, 6.83850476e-11, 4.54188483e-11, 5.39619601e-11,\n",
      "        6.03415307e-11, 5.08099061e-11],\n",
      "       [2.44195883e-13, 1.67529536e-12, 1.79180689e-12, 5.47466655e-13,\n",
      "        9.33383521e-01, 1.34855223e-12, 9.21430401e-13, 1.07898093e-12,\n",
      "        1.23079858e-12, 1.03323216e-12],\n",
      "       [6.51036391e-05, 4.96515188e-04, 5.10503061e-04, 1.52878242e-04,\n",
      "        8.01258469e-01, 3.89368876e-04, 2.57495417e-04, 3.06344429e-04,\n",
      "        3.53451362e-04, 2.89732915e-04],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [1.48816833e-03, 2.66336498e-02, 1.55574359e-02, 4.06969191e-03,\n",
      "        3.54724738e-02, 2.28489737e-02, 3.23047102e-03, 1.27787348e-02,\n",
      "        3.15701580e-03, 5.14051142e-03]]))\n"
     ]
    }
   ],
   "source": [
    "print((topic_model.get_representative_docs()[3]))\n",
    "print(topic_model.transform(topic_model.get_representative_docs()[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Try topic modeling per sentence instead of per review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the reviews, take the average sentiment value of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is only needed once\n",
    "# import nltk\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "reviews = product_df['review_body'].to_list()\n",
    "compounds = list()\n",
    "for review in reviews:\n",
    "    compounds.append(sia.polarity_scores(review)['compound'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the average sentiment value of each topic, and calculate the deviation of each review from each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sents = [0]*nr_topics\n",
    "cum_weights = [0]*nr_topics\n",
    "topic_model_info = topic_model.get_topic_info().drop([0]).reset_index()\n",
    "for index, compound in enumerate(compounds):\n",
    "    for topic, row in topic_model_info.iterrows():\n",
    "        weight = predictions[1][index][topic]\n",
    "        sents[topic] += weight*compound\n",
    "        cum_weights[topic] += weight\n",
    "average_sents = [0]*nr_topics\n",
    "for i in range(nr_topics):\n",
    "    average_sents[i] = sents[i] / cum_weights[i]\n",
    "\n",
    "## average_sents is now a value between 0 and 2 for each topic\n",
    "\n",
    "deviations = list()\n",
    "for index, review in enumerate(reviews):\n",
    "    deviation_per_topic = list()\n",
    "    for topic in range(nr_topics):\n",
    "        deviation_per_topic.append(np.abs(compounds[index] - average_sents[topic]))\n",
    "    deviations.append(deviation_per_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the $L_2$ norm of each word vector of each review, then calculate the average per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader\n",
    "\n",
    "w2v = gensim.downloader.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_norms = list()\n",
    "for review in reviews:\n",
    "    total_norm = 0\n",
    "    valid_words = 0\n",
    "    for word in review.split():\n",
    "        try:\n",
    "            total_norm += np.linalg.norm(w2v[word])\n",
    "            valid_words += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    try:\n",
    "        avg_norm = total_norm / valid_words\n",
    "        avg_norms.append(avg_norm)\n",
    "    except ZeroDivisionError:\n",
    "        avg_norms.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank all the reviews according to the topic relevance, average sentiment value and information estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = list()\n",
    "alpha = 0.1\n",
    "beta = 0.05\n",
    "topic_relevance = predictions[1]\n",
    "for topic in range(nr_topics):\n",
    "    ranking = pd.DataFrame(data={'review': reviews, 'relevance': np.transpose(topic_relevance)[topic], 'sentiment_deviation': np.transpose(deviations)[topic], 'information': avg_norms})\n",
    "    ranking['score'] = ranking['relevance'] + alpha*ranking['sentiment_deviation'] + beta*ranking['information']\n",
    "    ranking = ranking.sort_values(by=['score'], ascending=False)\n",
    "    rankings.append(ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the reranked 100 reviews of each topic of the most reviewed amazon product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90d3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from src.summarization.huggingface_summarizer import summarize_text\n",
    "\n",
    "print(summarize_text(reviews[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the information value of the summary with the next word predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the relevance of the summary to the product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the most common English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('researchTopics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b30b14a64463b48a472ddf210762c2b31ca134fd217a9af0c6fba74bd25d541d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
